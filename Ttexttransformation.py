# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rYlZbfQhBx-EeGdbuzf31Cm1XeelsBnt
"""

!pip install gensim
import pandas as pd
from gensim.models import Word2Vec
from sklearn.decomposition import PCA
from google.colab import drive

# 挂载Google Drive
drive.mount('/content/drive')

# Read the initial dataset
df = pd.read_csv('/content/drive/My Drive/clean_churn.csv')

# Ensure Surname column is string type for processing
df['Surname'] = df['Surname'].astype(str)

# Prepare unique surnames for Word2Vec training
sentences = df['Surname'].unique().tolist()
sentences = [s.split() for s in sentences]

# Train Word2Vec model
model = Word2Vec(sentences, vector_size=50, window=3, min_count=1)

# Initialize a list to hold the vectors. This handles missing surnames in the Word2Vec model.
vectors = []
for surname in df['Surname']:
    if surname in model.wv:
        vectors.append(model.wv[surname])
    else:
        # If the surname isn't in the model, use a zero vector instead.
        vectors.append([0]*50)

# Convert the vectors to a DataFrame
surname_vectors_df = pd.DataFrame(vectors)

# Apply PCA
pca = PCA(n_components=10)
surname_pca = pca.fit_transform(surname_vectors_df)

# Turn the PCA results into a DataFrame with an index matching the original df
surname_pca_df = pd.DataFrame(surname_pca, index=df.index,
                              columns=['pca_' + str(i) for i in range(10)])

# Merge the PCA features DataFrame with the original df
df_combined = pd.concat([df, surname_pca_df], axis=1)

df_combined.drop('Surname', axis=1, inplace=True)

# Save the combined dataset
df_combined.to_csv('/content/drive/My Drive/combined_dataset.csv', index=False)



"""# 新段落"""