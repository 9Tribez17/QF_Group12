{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3JNFY9imQ-4",
        "outputId": "7b13cb3c-e6fd-4c19-a277-bab1becb1839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# 上传数据并读取\n",
        "# 导入库\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# 挂载Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 读取Google Drive中的文件\n",
        "df = pd.read_csv('/content/drive/My Drive/clean_churn.csv')\n",
        "\n",
        "# 确保Surname列是字符串类型\n",
        "df['Surname'] = df['Surname'].astype(str)\n",
        "\n",
        "# 准备Word2Vec训练数据，这里我们使用姓氏的唯一值\n",
        "sentences = df['Surname'].unique().tolist()\n",
        "sentences = [s.split() for s in sentences]  # 分割每个姓氏成单独的单词\n",
        "\n",
        "# 训练Word2Vec模型\n",
        "model = Word2Vec(sentences, vector_size=50, window=3, min_count=1)\n",
        "\n",
        "\n",
        "# 将姓氏转换为Word2Vec向量\n",
        "surname_vectors = pd.DataFrame([model.wv[s[0]] for s in sentences if len(s) > 0])\n",
        "\n",
        "# 使用PCA降维到10个主成分\n",
        "pca = PCA(n_components=10)\n",
        "surname_pca = pca.fit_transform(surname_vectors)\n",
        "\n",
        "# 将PCA结果存入新的DataFrame\n",
        "surname_pca_df = pd.DataFrame(surname_pca, columns=['pca_' + str(i) for i in range(surname_pca.shape[1])])\n",
        "\n",
        "surname_pca_df.to_csv('/content/drive/My Drive/surname_pca.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fPMJd2i-HvW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 新段落"
      ],
      "metadata": {
        "id": "iJAUdj3IpM-z"
      }
    }
  ]
}